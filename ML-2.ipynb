{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c197238-e4bf-41ca-83e7-449b262d8674",
   "metadata": {},
   "source": [
    "# 붓꽃 품종 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febdc222-5099-4a0c-863e-71af2e2d7adf",
   "metadata": {},
   "source": [
    "사이킷런을 통해 첫 번째로 만들어볼 머신러닝 모델은 붓꽃 데이터 세트로 붓꽃의 품종을 분류하는 것이다. 붓꽃 데이터 세트는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처를 기반으로 꽃의 품종을 예측하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12200191-d9be-40eb-88a8-c84a5780230d",
   "metadata": {},
   "source": [
    "분류(Classification)는 대표적인 지도학습 방법의 하나로, 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad8bb15-682e-407e-a9ea-449a74b1d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target 값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris.data는 Iris 데이터 세트에서 피처만으로 데이터를 numpy로 가지고 있다\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris.target은 붓꽃 데이터세트에서 레이블 데이터를 numpy로 가지고 있다\n",
    "iris_label = iris.target\n",
    "print('iris target 값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
    "iris_df = pd.DataFrame(iris_data, columns = iris.feature_names)\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774ffcf-6e5b-4935-b140-112273652873",
   "metadata": {},
   "source": [
    "피처에는 sepal length, sepal width, petal length, petal width가 있다. 레이블은 0,1,2 세 가지 값으로 돼 있으며 0이 Setosa 품종, 1이 versicolor 품종, 2가 virginica 품종을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a922d-7280-481f-975b-ce8bcdf5328f",
   "metadata": {},
   "source": [
    "다음으로 학습용 데이터와 테스트용 데이터를 분리해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f35431e-566e-4c73-8634-b948ee3d2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59983f24-b77c-4ed9-8020-d0fdf5ff229f",
   "metadata": {},
   "source": [
    "학습 데이터를 확보했으니 의사 결정 트리를 이용해 학습과 예측을 수행해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b19ce3-724b-4ed2-8847-c9e608645cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d07de9-f30b-460d-a167-93e991318655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd14de-6311-4748-a0f3-753cf33af5ba",
   "metadata": {},
   "source": [
    "학습한 의사 결정 트리의 알고리즘 예측 정확도가 약 93.33%로 측정되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4b9f5-28ee-499c-90d0-cb75a2275136",
   "metadata": {},
   "source": [
    "# 사이킷런의 기반 프레임워크 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f630610-f36f-4e3f-8159-7c287cb438fa",
   "metadata": {},
   "source": [
    "## Estimator 이해 및 fit(), predict() 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581252a9-cd46-4bf9-b782-a41e45ad7f3e",
   "metadata": {},
   "source": [
    "사이킷런은 ML 모델 학습을 위해 fit()을, 학습된 모델의 예측을 위해 predict() 메서드를 제공한다. 분류 알고리즘을 구현한 클래스를 Classifier로, 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭한다. 사이킷런은 매우 많은 유형의 Classifier와 Regressor 클래스를 제공한다. 그리고 이들을 합쳐서 Estimator 클래스라고 부른다. 이 클래스 역시 fit()과 predict를 내부에서 구현하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c89fa-a3b9-41fb-bb15-3ad9fc398e61",
   "metadata": {},
   "source": [
    "## 사이킷런의 주요 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca257ee-32ae-4c0a-bc06-6b3d8a2432e8",
   "metadata": {},
   "source": [
    "* sklearn.dataset 사이킷런에 내장되어 예제로 제공하는 데이터 세트\n",
    "* sklearn.preprocessing 데이터 전처리에 필요한 다양한 가공 기능 제공\n",
    "* sklearn.feature_selection 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공\n",
    "* sklearn.feature_extraction 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는 데 사용\n",
    "* sklearn.model_selection 교차 검증을 위한 학습용/테스트용 분리, 그리드 서치로 최적 파라미터 추출 등의 API 제공\n",
    "* sklearn.metrics 분류, 회귀, 클러스터링, 페어와이즈에 대한 다양한 성능 측정 방법 제공\n",
    "* sklearn.ensemble 앙상블 알고리즘 제공\n",
    "* sklearn.linear_model 회귀 관련 알고리즘을 지원(SGD 관련 알고리즘도 제공)\n",
    "* sklearn.naive_bayes 나이브 베이즈 알고리즘 제공\n",
    "* sklearn.neighbors 최근접 이웃 알고리즘 제공\n",
    "* sklearn.svm 서포트 벡터 머신 알고리즘 제공\n",
    "* sklearn.tree 의사 결정 트리 알고리즘 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a916a-c2a5-40b9-a859-31e129d41230",
   "metadata": {},
   "source": [
    "## 내장된 예제 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9f2b9-9cff-47b1-9ed2-763207a10f44",
   "metadata": {},
   "source": [
    "* datasets.load_boston() 회귀 용도로, 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트\n",
    "* datasets.load_breast_cancer() 분류 용도로, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트\n",
    "* datasets.load_diabetes() 회귀 용도이며, 당뇨 데이터 세트\n",
    "* datasets.load_digits() 분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트\n",
    "* datasets.load_iris() 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659c7bc-8be0-4540-8e78-58cc3973e507",
   "metadata": {},
   "source": [
    "이 외에도 많다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce8e9e-52f7-48f0-82fd-145e84bc26be",
   "metadata": {},
   "source": [
    "load_iris() API의 반환 결과는 sklearn.utils,Bunch 클래스이다. 이는 파이썬 딕셔너리 자료형과 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f939495b-6395-4f8a-8977-1d50637e5b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ca0c5-177a-49dd-9ab2-04420db87184",
   "metadata": {},
   "source": [
    "데이터 키는 피처들의 데이터 값을 가리킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ec9bad-dddc-45be-b6a7-7be5c95ac5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3f4dcf-9c7f-4a1f-a734-dbcaace8a955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names의 type: <class 'list'>\n",
      "feature_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      "target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target의 type: <class 'numpy.ndarray'>\n",
      "target의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('feature_names의 type:', type(iris_data.feature_names))\n",
    "print('feature_names의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print('target_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.data))\n",
    "print('data의 shape:', iris_data.data.shape)\n",
    "print(iris_data.data)\n",
    "\n",
    "print('\\n target의 type:', type(iris_data.target))\n",
    "print('target의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ec1c1-c860-4774-a8b0-5fdf5a2fd5f3",
   "metadata": {},
   "source": [
    "# Model Selection 모듈 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedaeab-969c-48e3-b5f6-e1538fa71704",
   "metadata": {},
   "source": [
    "## 학습/테스트 데이터 세트 분리 - train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff48d43-352f-406e-b88e-45057fa821fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측  수행\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도:', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce571b-a90f-4ebb-b1e2-35324aeccf4e",
   "metadata": {},
   "source": [
    "정확도가 100%인 이유는 학습 데이터 세트를 기반으로 예측했기 때문이다. 즉, 모의고사를 이미 한 번 보고 답을 알고 있는 상태에서 모의고사 문제와 똑같은 본고사 문제가 출제됐기 때문이다. 따라서 예측을 수행하는 데이터 세트는 학습용 데이터 세트가 아닌 테스트 데이터 세트이어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292f87c-565b-4777-a174-b53f124189f2",
   "metadata": {},
   "source": [
    "train_test_split()를 통해 원본 데이터 세트를 학습용/테스트용 데이터 세트로 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356140ea-af02-418d-8cb2-e9c2f53c902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(f'예측 정확도: {accuracy_score(y_test, pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a6112-d587-4426-80c2-bac2c0c53996",
   "metadata": {},
   "source": [
    "테스트 데이터로 예측을 수행한 결과 약 95.56%이다. 붓꽃 데이터는 150개로 양이 크지 않아 전체 30% 정도인 테스트 데이터는 45개 정도밖에 되지 않으므로 예측 성능을 판단하기에는 그리 적절하지 않다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba965e-ba39-46ac-88e1-176731717648",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1aa78-0981-4cc9-a8d3-a3e6b210bf2f",
   "metadata": {},
   "source": [
    "앞에서 예측 성능을 평가하기 위한 별도의 테스트용 데이터가 필요하다고 했다. 하지만 이 방법 역시 과적합에 취약한 약점을 가질 수 있는데, 이러한 문제점을 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다. 즉, 본 고사를 치르기 전에 모의고사를 여러 번 보는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a165e-ae9d-42b1-bfc5-63d4682c380e",
   "metadata": {},
   "source": [
    "K 폴드 교차 검증은 K개의 데이터 폴드 세트를 만들어 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f777aa5-cc20-4fb3-ae4a-77d761f771cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7376bc-f242-4c62-a40c-f8e83e2bb7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f3c08-36e3-4b03-a82c-27628809ab1d",
   "metadata": {},
   "source": [
    "위의 결과를 보면 평균 검증 정확도는 0.9이다. 그리고 교차 검증 시마다 검증 세트의 인덱스가 달라짐을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bfc2e-feb7-4ed2-ab47-2dd3361dc8d1",
   "metadata": {},
   "source": [
    "Stratified K 폴드는 K 폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2216ea6-5dd5-4e19-b0a2-28fc5f9bd921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2d0fd5c-f69a-426d-a1cd-0273d97304f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "2    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6544bc4-e40e-4934-9415-c02befc9c67a",
   "metadata": {},
   "source": [
    "교차 검증 시마다 3개의 폴드 세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었다. 예로 첫 번째 교차 검증에서, 학습 레이블의 1, 2값이 각각 50개가 추출되었고, 검증 레이블 0 값이 50개 추출되었다. 하지만 학습 레이블은 1, 2 밖에 없으므로 0을 전혀 학습하지 못하고, 반대로 검증 레이블은 0 밖에 없으므로 학습 모델은 절대 0을 예측할 수 없다. \n",
    "\n",
    "StratifiedKFold는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf998b6-cf1c-4483-b552-c2bd7a4bb2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8c5b3-91a8-4483-9b13-af0305db6610",
   "metadata": {},
   "source": [
    "위의 결과를 보면 학습 레이블과 검증 레이블 데이터 값의 분포도가 거의 동일하게 할당됐음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ac5b0-6570-4443-bc82-7abf30278b54",
   "metadata": {},
   "source": [
    "사이킷런은 교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API를 제공한다. 대표적인 것이 cross_val_score()이다. KFold는 폴드 세트를 설정하고 for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출한 뒤, 반복적으로 학습과 예측을 수행하고 예측 성능을 반환했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b12012-d5d0-48a6-b95c-640003c315ff",
   "metadata": {},
   "source": [
    "cross_val_score()는 이런 일련의 과정을 한꺼번에 수행해주는 API이다. cross_val_score() 수행 후 반환 값은 scoring 파라미터로 지정된 **성능 지표 측정값**을 배열 형태로 반환단다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a52e64b-ce16-4ce0-a8e3-00db57242be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.92 0.98]\n",
      "평균 검증 정확도: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도, 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04482b15-6e7a-43bd-a13e-61cd8a7f94dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
